{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIO727P - Bioinformatics Software Development Group Project (2019/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AIM: To append extra inhibitor information found on http://www.icoa.fr/pkidb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python version: Python 3.7.4\n",
    "\n",
    "# import the required packages\n",
    "\n",
    "!pip install chembl_webresource_client\n",
    "!pip install pandas\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "from chembl_webresource_client.new_client import new_client\n",
    "import urllib.request\n",
    "import re # import regular expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 1:__ Load in the chEMBL accession IDs found on http://www.icoa.fr/pkidb/ that weren't present in the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_chembl=pd.read_table(\"extra_chembls.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2:__ Convert the IDs to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds=list(extra_chembl.chEMBL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3:__ Create an empty dictionary and add the chEMBL IDs as the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds2targets = dict()\n",
    "\n",
    "for x in compounds:\n",
    "    compounds2targets[x] = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 4:__ Using compound IDs, we can then go and find which proteins the inhibitors act on. These targets found are in terms of as chEMBL IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have our chEMBL IDs, we can process them in chunks\n",
    "\n",
    "chunk_size = 50\n",
    "\n",
    "for i in range(0, len(compounds), chunk_size):\n",
    "    # we jump from compounds to targets through activities:\n",
    "    activities = new_client.activity.filter(molecule_chembl_id__in=keys[i:i + chunk_size]).only(\n",
    "        ['molecule_chembl_id', 'target_chembl_id'])\n",
    "    # extracting target ChEMBL IDs from activities:\n",
    "    for act in activities:\n",
    "        compounds2targets[act['molecule_chembl_id']].add(act['target_chembl_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 5:__ Convert the chEMBL target IDs into UniProt IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in compounds2targets.items():\n",
    "    # We don't know how many targets are assigned to a given compound so again it's\n",
    "    # better to process targets in chunks:\n",
    "    lval = list(val)\n",
    "    uniprots = set()\n",
    "    for i in range(0, len(val), chunk_size):\n",
    "        targets = new_client.target.filter(target_chembl_id__in=lval[i:i + chunk_size]).only(\n",
    "            ['target_components'])\n",
    "        uniprots |= set(\n",
    "            sum([[comp['accession'] for comp in t['target_components']] for t in targets],[]))\n",
    "    compounds2targets[key] = uniprots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 6:__ Now we want to map the chEMBL compound IDs to UniProt IDs, i.e. 1-to-1 in the same dataframe, and create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the chEMBL IDs and uniprot IDs as lists from the dictionary\n",
    "\n",
    "chemblid=list(compounds2targets.keys())\n",
    "uniprot=list(compounds2targets.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open up new lists to form the dataframe\n",
    "\n",
    "UniProtKB=[]\n",
    "chEMBL_ID=[]\n",
    "\n",
    "# for every uniprot id, append the corresponding chEMBL ID to a list, and the uniprot id, to make a one-on-one mapping table\n",
    "\n",
    "for y in range(len(chemblid)):\n",
    "    for j in range(len(uniprot[y])):\n",
    "        chEMBL_ID.append(chemblid[y])\n",
    "        UniProtKB.append((list(uniprot[y])[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhib_kin=pd.DataFrame({'UniProt_ID' : UniProtKB})\n",
    "inhib_kin['chEMBL_ID']=chEMBL_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 7:__ Remove the targets that aren't found in the human kinase list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the uniprot accession numbers dataframe and extract the IDs as a list\n",
    "\n",
    "human_kinases=pd.read_csv(\"uniprot_acc_nums.csv\")\n",
    "kinase_list=list(human_kinases.UniProt_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=[]\n",
    "\n",
    "# if the uniprot id from the compound-target mapping isn't in the human kinase uniprot list, then append the index of the \n",
    "# compound-mapping uniprot id to a list\n",
    "\n",
    "for k in range(len(UniProtKB)):\n",
    "    pos=UniProtKB[k]\n",
    "    if pos not in kinase_list:\n",
    "        index.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhib_kin2=inhib_kin.drop(index) # drop the uniprot ids that aren't in the human kinase list. by doing this, we may remove some \n",
    "# of the initial inhibitors because they aren't linked to any of the human kinases in the uniprot list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 8:__ Convert chEMBL IDs to BindingDB IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of individual inhibitors by removing duplicates in the inhib-kin template dataframe\n",
    "\n",
    "inhib_kin3=inhib_kin2.drop_duplicates(subset=['chEMBL_ID'], keep='first')\n",
    "\n",
    "inhib_kin3.reset_index() # reset the indexing of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of the new chEMBL IDs that are linked to the human kinase inhibitors\n",
    "\n",
    "new_chembls=list(inhib_kin3.chEMBL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open up new lists to append new information to\n",
    "\n",
    "BindingDB=[]\n",
    "failed_list=[]\n",
    "\n",
    "for b in range(len(new_chembls)):\n",
    "    try:\n",
    "        # this url takes a query chEMBL ID and maps it to the corresponding monomerid/bindingdb id\n",
    "        unichem_url=\"https://www.ebi.ac.uk/unichem/rest/src_compound_id/\"+new_chembls[b]+\"/1\"\n",
    "        unichem_webpage=urllib.request.urlopen(unichem_url)\n",
    "        unichem_file=unichem_webpage.read().decode()\n",
    "        try:\n",
    "            # using regex extract the chEMBL ID\n",
    "            binding_pattern=re.compile(r\"{\\\"src_id\\\":\\\"31\\\",\\\"src_compound_id\\\":\\\"(.*?)\\\"}\")\n",
    "            binding_match=binding_pattern.search(unichem_file)\n",
    "            BindingDB.append(binding_match.group(1))\n",
    "            \n",
    "        except:\n",
    "            # if chEMBL ID can't be mapped to the bindingdb id then append an N/A\n",
    "            BindingDB.append(\"N/A\")\n",
    "            \n",
    "    except:\n",
    "        # any errors that occur can be appended to the failed list\n",
    "        failed_list.append(new_chembls[b])\n",
    "        BindingDB.append(\"N/A\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 9:__ Add the bindingDB information for all entries manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually find the bindingDB info for the above monomer IDs\n",
    "\n",
    "Ki=[\"2\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\",\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \n",
    "   \"\", \"\"]\n",
    "IC50=[\"\", \"\", \"\", \"9000\", \"\", \"\", \"20000\", \"5\", \"\", \"\", \"\", \"\", \"27\", \"4\", \"\", \"10000\", \"\", \"\", \"4800\", \"\", \"\", \"\", \"\", \"\", \"\", \n",
    "     \"1.3\", \"\", \"5\", \"3.38\", \"\", \"0.8\", \"\", \"22.3\"]\n",
    "Kd=[\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"2.1\", \"1200\", \"\", \"\", \"\", \"\", \"\", \"1000\", \"\", \"11\", \"\", \"\", \"\", \"\", \"\", \n",
    "   \"\", \"\", \"\", \"\", \"\"]\n",
    "EC50=[\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\",\n",
    "      \"\", \"\", \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 10:__ Iterate through the chEMBL ID list and use HTML source code to extract the relevant information about the inhibitors from chEMBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_id=new_chembls\n",
    "\n",
    "chEMBL=[]\n",
    "molecule_name=[]\n",
    "molecule_type=[]\n",
    "molecular_formula=[]\n",
    "molecular_weight=[]\n",
    "synonyms=[]\n",
    "\n",
    "failed_list=[]\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for c in range(len(ch_id)):\n",
    "    # open the compound id page for each element in the list\n",
    "    ebi_url=\"https://www.ebi.ac.uk/chembl/compound_report_card/\"+ch_id[c]+\"/\"\n",
    "    ebi_webpage=urllib.request.urlopen(ebi_url)\n",
    "    ebi_file=ebi_webpage.read().decode()\n",
    "    counter = counter + 1\n",
    "    print (counter)\n",
    "    \n",
    "    try:\n",
    "        # as some chembl id entries don't have an inhibitor name associated with them in the 'Compound:' field, but do have a \n",
    "        # name associated with it in the 'Synonyms:' field, to avoid including inhibitors without an official name, we can \n",
    "        # skip those entries as they won't be as useful to us\n",
    "        \n",
    "        syn_pattern=re.compile(r\"Synonyms: (.*?)\\\"/>\")\n",
    "        syn_match=syn_pattern.search(ebi_file)\n",
    "        \n",
    "        name_pattern=re.compile(r\"Compound: (.*?)\\\"\\/\")\n",
    "        name_match=name_pattern.search(ebi_file)\n",
    "        \n",
    "        # once the entry has an inhibitor name and synonyms associated with it, we can extract the other information associated\n",
    "        # with the inhibitor\n",
    "            \n",
    "        info_pattern=re.compile(r\"Molecule Type: (.*?), Molecular Formula: (.*?), Molecular Weight: (.*?), Synonyms: (.*?)\\\"/>\")\n",
    "        info_match=info_pattern.search(ebi_file)\n",
    "            \n",
    "        molecule_type.append(info_match.group(1))\n",
    "        molecular_formula.append(info_match.group(2))\n",
    "        molecular_weight.append(info_match.group(3))\n",
    "        synonyms.append(info_match.group(4).replace(\";\", \", \"))\n",
    "        \n",
    "        # also append the chembl id to the list so we know which accession number the info is associated with\n",
    "        chEMBL.append(ch_id[c])\n",
    "        \n",
    "        # sometimes the molecule name is just the chEMBL ID so to avoid that, we can append the synonym instead\n",
    "        if name_match.group(1) == ch_id[c]:\n",
    "            molecule_name.append(info_match.group(4))\n",
    "        elif name_match.group(1) != ch_id[c]:\n",
    "            molecule_name.append(name_match.group(1))\n",
    "    except:\n",
    "        # if there's no molecule name associated with the entry, we append it to the failed list\n",
    "        failed_list.append(ch_id[c])\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 11:__ Create structure image URLs for the inhibitors from chEMBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chEMBL_URL=[]\n",
    "\n",
    "for w in range(len(ch_id)):\n",
    "    chEMBL_URL.append(\"https://www.ebi.ac.uk/chembl/api/data/image/\"+ch_id[w]+\".png?bgColor=white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 12:__ It is known that all the inhibitors in the extra_chembls.txt file are in chEMBL, but one ID got excluded because it doesn't have any synonyms - this is a minor flaw of the code that could obviously be improved. However, to re-append it to the dataframe, the information was manually gathered up and re-inserted to the lists in the correct position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the index of the skipped inhibitor\n",
    "\n",
    "print (ch_id.index(\"CHEMBL1277072\"))\n",
    "\n",
    "# the position is 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually find the relevant information and append it back to the lists at the correct position\n",
    "\n",
    "chEMBL.insert(12, \"CHEMBL1277072\")\n",
    "molecule_name.insert(12, \"HENATINIB\")\n",
    "molecule_type.insert(12, \"Small molecule\")\n",
    "molecular_formula.insert(12, \"C25H29FN4O4\")\n",
    "molecular_weight.insert(12, \"468.53\")\n",
    "synonyms.insert(12, \"N/A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 13:__ Create unique accession numbers for the inhibitors table, starting from the last accession number in the original/main file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID=1431\n",
    "IN_ID=[]\n",
    "\n",
    "for x in range(len(chEMBL)):\n",
    "    ID = ID + 1\n",
    "    IN_ID.append(\"IN\"+str(ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 14:__ Create a new dataframe of all the information gathered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame({'BindingDB_ID' : BindingDB})\n",
    "df1['chEMBL_ID']=chEMBL\n",
    "df1['Ki_nM']=Ki\n",
    "df1['IC50_nM']=IC50\n",
    "df1['Kd_nM']=Kd\n",
    "df1['EC50_nM']=EC50\n",
    "df1['Molecule_name']=molecule_name\n",
    "df1['Molecule_type']=molecule_type\n",
    "df1['Molecular_formula']=molecular_formula\n",
    "df1['Molecular_weight']=molecular_weight\n",
    "df1['Synonyms']=synonyms\n",
    "df1['IN_ID']=IN_ID\n",
    "df1['chEMBL_URL']=chEMBL_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 15:__ Download the dataframe to check if it needs manual cleaning. The only thing that needed cleaning was in the 'Synonyms' column, whereby it contained a section on 'Trade Names:' for 5 inhibitors, and thus that needed to be removed from the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"extra_inhibs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 16:__ Load in the extra_inhibitors dataframe and original dataframes created using the 'SDP_inhibitors_dataframe.ipynb' script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhibs_main=pd.read_csv(\"inhibitors_dataframe.csv\")\n",
    "\n",
    "inhibs_extra=pd.read_csv(\"extra_inhibs.csv\")\n",
    "\n",
    "inhib_kin_main=pd.read_csv(\"inhib_kin_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 17:__ Append the original inhibitors dataframe to the extra inhibitors dataframe to create the final inhibitors dataframe, and export is as a final .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[inhibs_main, inhibs_extra]\n",
    "result = pd.concat(frames)\n",
    "result\n",
    "result.to_csv(\"final_inhibitors_dataframe.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 18:__ Create the extra inhibitors dataframe as outlined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire lists of the uniprot to chEMBL ID mappings\n",
    "\n",
    "ik_uniprot=list(inhib_kin2.UniProt_ID)\n",
    "ik_chembl=list(inhib_kin2.chEMBL_ID)\n",
    "\n",
    "# create the dataframe with the first column being the UniProt ID\n",
    "\n",
    "inhib_kin_extra=pd.DataFrame({'UniProt_ID' : ik_uniprot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open new lists to form the basis of the columns in the inhib kin\n",
    "\n",
    "ik_binding=[]\n",
    "ik_molecule=[]\n",
    "ik_id=[]\n",
    "IK=54761\n",
    "\n",
    "# this loops acts like dictionary. it takes the chEMBL id of the inhib-kin list (that maps to the uniprot id), and then finds\n",
    "# the index of it in the inhibitor chEMBL id list, using this index we can acquire the bindingdb ID and molecule name from the\n",
    "# inhibitors table and append it to the ik_binding and ik_molecule lists to form the columns of the inhib-kin dataframe\n",
    "\n",
    "# this list also incoporates the accession number creating loop starting from the last accession number in the main dataframe\n",
    "\n",
    "for e in range(len(ik_chembl)):\n",
    "    iden=ik_chembl[e]\n",
    "    i=chEMBL.index(iden)\n",
    "    ik_binding.append(BindingDB[i])\n",
    "    ik_molecule.append(molecule_type[i])\n",
    "    IK=IK + 1\n",
    "    ik_id.append(\"IK\"+str(IK))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 19:__ Append the extra inhib_kin dataframe to the original inhib_kin dataframe, and export is as a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhib_kin_extra['BindingDB_ID']=ik_binding\n",
    "inhib_kin_extra['chEMBL_ID']=ik_chembl\n",
    "inhib_kin_extra['Molecule_name']=ik_molecule\n",
    "inhib_kin_extra['IN_KI']=ik_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames2=[inhib_kin_main, inhib_kin_extra]\n",
    "result2 = pd.concat(frames2)\n",
    "result2.to_csv(\"final_inhib_kin_dataframe.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
